#!/usr/bin/env python3
"""
Calculate comprehensive UMI QC metrics from FASTQ files with extracted UMIs
"""

import sys
import gzip
import json
import argparse
from collections import Counter
from math import log2

def calculate_shannon_entropy(umi_counts):
    """Calculate Shannon entropy of UMI distribution"""
    total = sum(umi_counts.values())
    if total == 0:
        return 0.0
    
    entropy = 0.0
    for count in umi_counts.values():
        if count > 0:
            p = count / total
            entropy -= p * log2(p)
    return entropy

import math

def expected_duplicate_rate(n: int, umi_length: int) -> float:
    """
    Expected fraction of reads that are duplicates due to random UMI collision.
    E[duplicate rate] = 1 - (E[unique UMIs] / n)
    """
    if n == 0:
        return 0.0
    m = 4 ** umi_length
    expected_unique = m * (1.0 - math.exp(-n / m))
    return max(0.0, min(1.0, 1.0 - (expected_unique / n)))

def expected_num_colliding_pairs(n: int, umi_length: int) -> float:
    """
    Expected number of UMI colliding pairs using birthday problem.
    For n molecules drawn from m=4^L possible UMIs:
    E[colliding pairs] ≈ n(n-1)/(2m)
    """
    if n <= 1:
        return 0.0
    m = 4 ** umi_length
    return (n * (n - 1)) / (2.0 * m)

def expected_num_unique_umis(n: int, umi_length: int) -> float:
    """
    Expected number of unique UMIs observed out of n molecules.
    E[unique UMIs] = m * (1 - (1 - 1/m)^n) ≈ m * (1 - exp(-n/m))
    where m = 4^L
    """
    if n == 0:
        return 0.0
    m = 4 ** umi_length
    # For large m, use approximation to avoid numerical issues
    return m * (1.0 - math.exp(-n / m))

def expected_fraction_molecules_colliding(n: int, umi_length: int) -> float:
    """
    Expected fraction of molecules involved in at least one UMI collision.
    This is: 2 * E[colliding pairs] / n
    (Each collision involves 2 molecules)
    """
    if n == 0:
        return 0.0
    expected_pairs = expected_num_colliding_pairs(n, umi_length)
    return (2.0 * expected_pairs) / n

def prob_at_least_one_umi_collision(n: int, umi_length: int) -> float:
    """
    Probability that at least one UMI collision occurs (birthday problem).
    P(at least one collision) = 1 - exp(-n(n-1)/(2m))
    where m = 4^L, n = number of molecules
    """
    if n <= 1:
        return 0.0
    m = 4 ** umi_length
    return 1.0 - math.exp(-(n * (n - 1)) / (2.0 * m))

def parse_fastq_with_umi(fastq_file):
    """
    Parse FASTQ file and extract UMI information from read headers
    Assumes UMI is in the read ID after extraction by umi_tools
    Format: @READ_ID_UMI or @READ_ID_UMI:SEQUENCE
    
    Note: After umi_tools extract, UMI quality scores are NOT available in the FASTQ.
    The UMI has been moved to the header and removed from the sequence.
    Quality information must be obtained from the umi_tools extract log.
    """
    umi_counts = Counter()
    total_reads = 0
    
    opener = gzip.open if fastq_file.endswith('.gz') else open
    
    with opener(fastq_file, 'rt') as f:
        while True:
            # Read 4 lines (FASTQ record)
            header = f.readline().strip()
            if not header:
                break
            
            seq = f.readline().strip()
            plus = f.readline().strip()
            _ = f.readline().strip()  # quality line (not used after UMI extraction)
            
            total_reads += 1
            
            # Extract UMI from header
            # Format after umi_tools extract: @READ_ID_UMI or @READ_ID_UMI:SEQUENCE
            # Get the read ID part (before first space)
            read_id = header.split()[0] if ' ' in header else header
            if '_' in read_id:
                umi_seq = read_id.split('_')[-1]
                # Check if it's a valid UMI (only ACGT characters)
                if umi_seq and all(c in 'ACGTN' for c in umi_seq):
                    umi_counts[umi_seq] += 1
    
    return umi_counts, None, total_reads

def parse_umi_only_fastq(umi_fastq_file):
    """
    Parse UMI-only FASTQ file to extract quality scores
    This file contains only UMI sequences with their original quality scores
    Generated by extract_umi_with_quality.py
    """
    from collections import defaultdict
    
    umi_qualities = defaultdict(list)
    total_umis = 0
    
    opener = gzip.open if umi_fastq_file.endswith('.gz') else open
    
    with opener(umi_fastq_file, 'rt') as f:
        while True:
            # Read 4 lines (FASTQ record)
            header = f.readline().strip()
            if not header:
                break
            
            umi_seq = f.readline().strip()
            plus = f.readline().strip()
            umi_qual = f.readline().strip()
            
            if umi_seq and umi_qual:
                umi_qualities[umi_seq].append(umi_qual)
                total_umis += 1
    
    return umi_qualities, total_umis

def calculate_quality_score(qual_string):
    """Calculate average Phred quality score from quality string"""
    if not qual_string:
        return 0.0
    return sum(ord(c) - 33 for c in qual_string) / len(qual_string)

def calculate_metrics(umi_counts, umi_qualities, total_reads, umi_length):
    """Calculate comprehensive UMI QC metrics"""
    
    unique_umis = len(umi_counts)
    total_umis = sum(umi_counts.values())
    
    # Basic metrics
    metrics = {
        'total_reads': total_reads,
        'total_umis': total_umis,
        'unique_umis': unique_umis,
        'umi_length': umi_length,
    }
    
    if total_umis == 0:
        return metrics
    
    # UMI diversity and complexity
    metrics['diversity_ratio'] = unique_umis / total_umis if total_umis > 0 else 0.0
    metrics['shannon_entropy'] = calculate_shannon_entropy(umi_counts)
    metrics['max_entropy'] = umi_length * 2  # Maximum possible entropy for DNA (log2(4) per position)
    metrics['complexity_score'] = metrics['shannon_entropy'] / metrics['max_entropy'] if metrics['max_entropy'] > 0 else 0.0
    
    # Collision metrics using birthday problem
    # n = number of unique UMIs observed (starting molecules for collision analysis)
    # Use unique_umis for birthday problem calculations
    metrics['expected_duplicate_rate'] = expected_duplicate_rate(unique_umis, umi_length)
    
    # Birthday problem collision statistics
    metrics['expected_num_colliding_pairs'] = expected_num_colliding_pairs(unique_umis, umi_length)
    metrics['expected_num_unique_umis'] = expected_num_unique_umis(unique_umis, umi_length)
    metrics['expected_fraction_molecules_colliding'] = expected_fraction_molecules_colliding(unique_umis, umi_length)
    metrics['prob_at_least_one_umi_collision'] = prob_at_least_one_umi_collision(unique_umis, umi_length)
    
    # Observed collision rate (empirical)
    # If we have N total molecules but only U unique UMIs, collision rate = (N-U)/N
    observed_collision_rate = (total_umis - unique_umis) / total_umis if total_umis > 0 else 0.0
    metrics['observed_collision_rate'] = observed_collision_rate
    
    # Family size statistics
    family_sizes = list(umi_counts.values())
    family_sizes.sort()
    
    metrics['mean_family_size'] = sum(family_sizes) / len(family_sizes)
    metrics['median_family_size'] = family_sizes[len(family_sizes) // 2]
    metrics['min_family_size'] = min(family_sizes)
    metrics['max_family_size'] = max(family_sizes)
    
    # Singleton rate (UMIs with only 1 read)
    singletons = sum(1 for count in umi_counts.values() if count == 1)
    metrics['singleton_count'] = singletons
    metrics['singleton_rate'] = singletons / unique_umis if unique_umis > 0 else 0.0
    
    # Amplification metrics
    metrics['amplification_ratio'] = metrics['mean_family_size']  # Same as mean family size
    
    # UMI quality - overall and per-position
    if umi_qualities:
        all_qualities = []
        position_qualities = [[] for _ in range(umi_length)]  # Track quality per position
        
        for umi, qual_list in umi_qualities.items():
            for qual_str in qual_list:
                # Overall quality
                all_qualities.append(calculate_quality_score(qual_str))
                
                # Per-position quality
                for pos, qual_char in enumerate(qual_str):
                    if pos < umi_length:
                        position_qualities[pos].append(ord(qual_char) - 33)
        
        # Overall quality metrics
        metrics['mean_umi_quality'] = sum(all_qualities) / len(all_qualities) if all_qualities else 0.0
        metrics['min_umi_quality'] = min(all_qualities) if all_qualities else 0.0
        metrics['max_umi_quality'] = max(all_qualities) if all_qualities else 0.0
        
        # Per-position quality metrics
        metrics['per_position_quality'] = []
        for pos in range(umi_length):
            if position_qualities[pos]:
                pos_mean = sum(position_qualities[pos]) / len(position_qualities[pos])
                pos_min = min(position_qualities[pos])
                pos_max = max(position_qualities[pos])
                metrics['per_position_quality'].append({
                    'position': pos + 1,  # 1-indexed
                    'mean_quality': pos_mean,
                    'min_quality': pos_min,
                    'max_quality': pos_max
                })
    else:
        metrics['mean_umi_quality'] = 0.0
        metrics['min_umi_quality'] = 0.0
        metrics['max_umi_quality'] = 0.0
        metrics['per_position_quality'] = []
    
    # Success rate (percentage of UMIs that would pass typical filters)
    # Typically: family size >= 2, quality >= 20
    passing_umis = sum(1 for umi, count in umi_counts.items() if count >= 2)
    metrics['success_rate'] = passing_umis / unique_umis if unique_umis > 0 else 0.0
    
    return metrics

def main():
    parser = argparse.ArgumentParser(description='Calculate UMI QC metrics')
    parser.add_argument('--fastq', required=True, help='Input FASTQ file with extracted UMIs')
    parser.add_argument('--sample', required=True, help='Sample name')
    parser.add_argument('--umi-length', type=int, default=12, help='UMI length')
    parser.add_argument('--output', required=True, help='Output metrics file')
    parser.add_argument('--multiqc', required=True, help='Output MultiQC JSON file')
    
    args = parser.parse_args()
    
    # Parse FASTQ and extract UMI information
    print(f"Processing {args.fastq}...", file=sys.stderr)
    umi_counts, umi_qualities, total_reads = parse_fastq_with_umi(args.fastq)
    
    # Calculate metrics
    metrics = calculate_metrics(umi_counts, umi_qualities, total_reads, args.umi_length)
    
    # Write metrics to file
    with open(args.output, 'w') as f:
        f.write(f"Sample: {args.sample}\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("Extraction Statistics:\n")
        f.write(f"  Total reads: {metrics['total_reads']:,}\n")
        f.write(f"  Total UMIs: {metrics['total_umis']:,}\n")
        f.write(f"  Unique UMIs: {metrics['unique_umis']:,}\n")
        f.write(f"  UMI length: {metrics['umi_length']}\n\n")
        
        f.write("UMI Diversity:\n")
        f.write(f"  Diversity ratio: {metrics['diversity_ratio']:.4f}\n")
        f.write(f"  Shannon entropy: {metrics['shannon_entropy']:.4f}\n")
        f.write(f"  Complexity score: {metrics['complexity_score']:.4f}\n")
        f.write(f"  Collision rate: {metrics['collision_rate']:.4f}\n\n")
        
        f.write("Family Size Statistics:\n")
        f.write(f"  Mean family size: {metrics['mean_family_size']:.2f}\n")
        f.write(f"  Median family size: {metrics['median_family_size']:.0f}\n")
        f.write(f"  Min family size: {metrics['min_family_size']}\n")
        f.write(f"  Max family size: {metrics['max_family_size']}\n")
        f.write(f"  Amplification ratio: {metrics['amplification_ratio']:.2f}\n\n")
        
        f.write("Singleton Analysis:\n")
        f.write(f"  Singleton count: {metrics['singleton_count']:,}\n")
        f.write(f"  Singleton rate: {metrics['singleton_rate']:.4f}\n\n")
        
        f.write("Quality Metrics:\n")
        f.write(f"  Mean UMI quality: {metrics['mean_umi_quality']:.2f}\n")
        f.write(f"  Min UMI quality: {metrics['min_umi_quality']:.2f}\n\n")
        
        f.write("Performance Metrics:\n")
        f.write(f"  Success rate: {metrics['success_rate']:.4f}\n")
    
    # Prepare plot data for MultiQC
    
    # 1. Family size distribution data
    family_sizes = list(umi_counts.values())
    family_size_dist = {}
    for size in range(1, min(max(family_sizes) + 1, 101)):  # Cap at 100 for display
        family_size_dist[size] = family_sizes.count(size)
    
    # 2. Top 20 UMIs
    top_umis = dict(umi_counts.most_common(20))
    
    # 3. UMI quality by position
    umi_quality_by_pos = {}
    if umi_qualities:
        for pos in range(args.umi_length):
            pos_qualities = []
            for umi, quals in umi_qualities.items():
                for qual_str in quals:
                    if len(qual_str) > pos:
                        pos_qualities.append(ord(qual_str[pos]) - 33)
            if pos_qualities:
                umi_quality_by_pos[pos + 1] = sum(pos_qualities) / len(pos_qualities)
    
    # Write MultiQC JSON with metrics and plots
    multiqc_data = {
        "id": f"umi_qc_{args.sample}",
        "plot_type": "generalstats",
        "pconfig": {
            "namespace": "UMI QC Metrics"
        },
        "data": {
            args.sample: {
                "total_reads": metrics['total_reads'],
                "total_umis": metrics['total_umis'],
                "unique_umis": metrics['unique_umis'],
                "umi_length": metrics['umi_length'],
                "diversity_ratio": metrics['diversity_ratio'],
                "shannon_entropy": metrics['shannon_entropy'],
                "complexity_score": metrics['complexity_score'],
                "collision_rate": metrics['collision_rate'],
                "mean_family_size": metrics['mean_family_size'],
                "median_family_size": metrics['median_family_size'],
                "min_family_size": metrics['min_family_size'],
                "max_family_size": metrics['max_family_size'],
                "singleton_count": metrics['singleton_count'],
                "singleton_rate": metrics['singleton_rate'],
                "amplification_ratio": metrics['amplification_ratio'],
                "mean_umi_quality": metrics['mean_umi_quality'],
                "min_umi_quality": metrics['min_umi_quality'],
                "success_rate": metrics['success_rate']
            }
        },
        "plot_data": {
            "family_size_distribution": {
                args.sample: family_size_dist
            },
            "top_umis": {
                args.sample: top_umis
            },
            "umi_quality_by_position": {
                args.sample: umi_quality_by_pos
            }
        }
    }
    
    with open(args.multiqc, 'w') as f:
        json.dump(multiqc_data, f, indent=2)
    
    print(f"Metrics written to {args.output}", file=sys.stderr)
    print(f"MultiQC data written to {args.multiqc}", file=sys.stderr)

if __name__ == '__main__':
    main()
